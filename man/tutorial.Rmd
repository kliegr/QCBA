---
title: "qCBA tutorial"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## About Quantitative CBA

We propose a postprocessing algorithm for ARC classification algorithm CBA (Liu, 1998), which reverts to the original attribute space to ``edit'' discovered association rules, refining the scope of literals in the antecedent of the rules.  As a consequence, the fit of the individual rules to data improves, rendering some of the rules comprising the model as redundant. These rules can be removed, making the resulting classifier smaller. The viable properties of CBA models that make these rule lists comprehensible, such as one-rule classification and crisp rules, are retained. The postprocessing is conceptually fast, because it is performed on a relatively small number of rules that passed the data coverage pruning in CBA. 

### Novelty

* First "quantitative" association rule classification algorithm.
* Conceptually different from existing quantitative association rule learning algorithms such as QuantMiner or  NAR-Discovery.

### Benchmark

QCBA was evaluated on 22 standard UCI datasets against standard as well as state-of-the-art symbolic classification algorithms (such as RIPPER, FURIA, CBA). The evaluation is fully reproducible using the [arcBench package](https://github.com/kliegr/arcBench) and meets industry standards (same folds, metaparameter optimization, etc.). The evaluation shows that QCBA produces  classifiers with about 1/3 less rules than CBA while retaining comparable accuracy. 

## Library
The QCBA implementation is in Java. It is also available via an [R package wrapper](https://github.com/kliegr/QCBA), which we will used for this example.

```{r results='hide', message=FALSE}
library(qCBA)
```
## Data

Let's look at sample data for this example. There are two explanatory attributes (Temperature and Humidity). The target attribute is preference (e.g. subjective comfort level). 


```{r results='hide', message=FALSE}
attach(humtemp)
```

The first few rows of the data.


```{r}
head(humtemp)
```

And a scatter plot.
```{r}
plot(Humidity,Temperature,pch=as.character(Class))
```

## Building a CBA classifier
Association rule learning requires discretized data.
In this case, we perform simple equidistant binning.


```{r}
  #custom discretization
  data_raw<-humtemp
  data_discr <- humtemp
  temp_breaks <- seq(from=15,to=45,by=5)
  hum_breaks <- c(0,40,60,80,100)
  temp_unique_vals <- setdiff(unique(Temperature),temp_breaks)
  hum_unique_vals <- setdiff(unique(Humidity),hum_breaks)
  data_discr[,1]<-cut(Temperature,breaks=temp_breaks)
  data_discr[,2]<-cut(Humidity,breaks=hum_breaks)
  #change interval syntax from (15,20] to (15;20], which is required by MARC
  data_discr[,1]<-as.factor(unlist(lapply(data_discr[,1], function(x) {gsub(",", ";", x)})))
  data_discr[,2]<-as.factor(unlist(lapply(data_discr[,2], function(x) {gsub(",", ";", x)})))
  
  data_discr[,3] <- as.factor(Class)
  head(data_discr)

```
The discretization split the data space into rectangular regions. Given that we have two attributes, the discovered rule can only correspond to a rectangular region with *borders aligned to the grid*. If we had more than two attributes, the discovered rule would delimit a hypercube.

```{r}
plotGrid <- function(plotFineGrid=TRUE, plotDiscrGrid=TRUE)
{
  if (plotDiscrGrid)
  {

    for (i in temp_breaks[-1])
  {
    abline(h=i, lty=2)
  }
  for (i in hum_breaks[-1])
  {
    abline(v=i, lty=2)
  }
  }
  if (plotFineGrid)
  {
    for (i in temp_unique_vals[-1])
    {
      abline(h=i, lty=3, col="grey")
    }
    for (i in hum_unique_vals[-1])
    {
      abline(v=i, lty=3, col="grey")
    }  
  }
}

plot(Humidity,Temperature,pch=as.character(Class))
plotGrid(FALSE)


```

The next step is mining of association rules. The rule mining is constrained to rules that have values of the Class attribute in the consequent.

```{r results='hide', message=FALSE}
sink("/dev/null")
classAtt="Class"
appearance <- getAppearance(data_discr, classAtt)
txns <- as(data_discr, "transactions")
  rules <- apriori(txns, parameter = list(confidence = 0.5, support= 3/nrow(data_discr), minlen=1, maxlen=3), appearance=appearance)
interestingRule <- inspect(rules)[5,] #will use this later
sink()
inspect(rules)
```

The rules can be visualized in the feature space as rectangular regions. 
<span style="color:red">Class 1 is coded  as red</span>, <span style="color:green">Class 2 as green</span> and <span style="color:blue">Class 4  as blue region</span>.

```{r}
interesting_rule <- 5
#as.character(Class)
plot(Humidity,Temperature,pch=Class,main="Discovered asociation rules",cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)

plotGrid(FALSE)

plotHumTempRule<- function(rules, ruleIndex)
{
  if (typeof(rules)=="S4")
  {
    # rules is a arules rule model
    # sink: inspect also sends rules to the standard output
    sink("/dev/null")
    r <- inspect(rules)[ruleIndex,]
    sink()
    rule <- paste(unlist(r$lhs[1]),collapse='')
    rhs <- paste(unlist(r$rhs[1]),collapse='')
  }
  else
  {
    # rules is a list of rules output by qCBA
    rule <- rules[ruleIndex,1]
    #rule <- rules$rules[ruleIndex]
    rhs <- regmatches(rule,regexec("\\{Class=.*\\}",rule))
  }
  #get color
  if (rhs == "{Class=1}")
  {
    border = "red"
    col=rgb(1.0,0.2,0.2,alpha=0.3)
  }
  else if (rhs == "{Class=2}")
  {
    border = "green"
    col=rgb(0,1,0,alpha=0.3)
  }
  else if (rhs == "{Class=3}")
  {
    border = "black"
    col=rgb(0.4,0.4,0.4,alpha=0.3)
  }
  else if (rhs == "{Class=4}")
  {
    border = "blue"
    col=rgb(0,0,1,alpha=0.3)
  }

  
  temp_coordinates<-unlist(regmatches(rule,regexec("Temperature=.([0-9]+);([0-9]+).",rule)))
  if (length(temp_coordinates)==0)
  {
    #if the temperature literal is missing in the rule, use the following coordinates
    temp_coordinates=c(0,0,50)
  }
  hum_coordinates<-unlist(regmatches(rule,regexec("Humidity=.([0-9]+);([0-9]+).",rule)))
  if (length(hum_coordinates)==0)
  {
    #if the humidity literal is missing in the rule, use the following coordinates
    hum_coordinates=c(0,0,100)
  }
  m <- rect(hum_coordinates[2], temp_coordinates[2], hum_coordinates[3], temp_coordinates[3],border=border,col=col)
}

plotRules <- function(rules)
{
  if (typeof(rules)=="S4") #for arules/cba
  {
    rule_count <- length(rules)
  }
  else #for qcba
  {
    rule_count <- nrow(rules)
  }
  for (i in 1:rule_count)
  {
    plotHumTempRule(rules,i)
  }
}
plotRules(rules)
#plotHumTempRule(rules,1,border = "red",col=rgb(0.8,0.2,0.2,alpha=0.3))
#plotHumTempRule(rules,2,border = "green",col=rgb(0,1,0,alpha=0.3))
#plotHumTempRule(rules,3,border = "blue",col=rgb(0,0,1,alpha=0.3))
#plotHumTempRule(rules,4,border = "blue",col=rgb(0,0,1,alpha=0.3))
#plotHumTempRule(rules,5,border = "blue",col=rgb(0,0,1,alpha=0.3))
#m <- dev.copy(png,filename="cba.png")
#m <- dev.off()
```


Out of the two discovered rules, we will create a CBA classifier.
This means that the rules will be 

1. sorted according to confidence support and length
2. subject to simultaneous data coverage pruning & default rule pruning:
 + data coverage pruning: algorithm iterates through the rules in the sort order removing any rule which does not correctly cover any instances (instances correctly covered by rules above the current rule have been removed)
 + default rule pruning: the algorithm iterates through the rules in the sort order, and cuts off the list once the current rule would result in worse accuracy than a default rule inserted at that place
4. a default rule is inserted at the bottom of the list. Default rule is a rule with empty antecedent and consequent predicting a majority class left in the training data once the previous rules in the classifier were applied.

```{r message=FALSE}
classAtt="Class"
  appearance <- getAppearance(data_discr, classAtt)
  # Note that we are calling `cba_manual()` instead of cba() because we want for demonstration purposes to construct the classifier from a user-generated rule list.
  rmCBA <- cba_manual(data_raw,  rules, txns, appearance$rhs, classAtt, cutp= list(), pruning_options=NULL)
```

In this case, CBA did not remove any rule, but  added a default rule to the end, which ensures that the rule list covers every possible instance.

```{r}
inspect(rmCBA@rules)
```

CBA added a default rule, therefore the complete instance space is now covered. The green background is associated with the default rule classifying to Class 2.

```{r}
plot(Humidity,Temperature,pch=Class,main="CBA model",cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
plotGrid(FALSE)
plotRules(rmCBA@rules)
```




The accuracy of this model on training data:
```{r results='hide', message=FALSE}

  prediction_cba<-predict(rmCBA,data_discr,discretize=FALSE)
  acc_cba <- CBARuleModelAccuracy(prediction_cba, data_discr[[classAtt]])
  print(paste("Accuracy (CBA):",acc_cba))
```
## Postprocessing CBA output with Quantitative CBA (QCBA)
QCBA postprocesses CBA classifier created over discretized numeric attributes. QCBA requires on the input also the original raw undiscretized (continuous) data. 


### Basic qCBA model

To build a model, `qcba` needs a cba model and raw (undiscretized) data. Note that number of additional parameters can be also specified - these were left to their default values.
```{r results='hide'}
trim_literal_boundaries <- TRUE #will use this variable later
rmqCBA <- qcba(cbaRuleModel=rmCBA,datadf=data_raw, extendType="numericOnly",trim_literal_boundaries = trim_literal_boundaries, postpruning = "cba", defaultRuleOverlapPruning="noPruning",  createHistorySlot=TRUE,loglevel = "WARNING")
print(rmqCBA@rules)
```

As we can notice, the number of rules on the output decreased. After the rule boundaries have been extended, postpruning removed two rules from the CBA model. The default rule was recomputed, and now classifies to green (Class 2).
```{r}
plot(Humidity,Temperature,pch=Class,main="QCBA model",cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
plotGrid(FALSE)
plotRules(rmqCBA@rules)
```
The accuracy of this model on training data:
```{r results='hide', message=FALSE}

  prediction_qcba<-predict(rmqCBA,data_raw,discretize=FALSE)
  acc_qcba <- CBARuleModelAccuracy(prediction_qcba, data_raw[[classAtt]])
  print(paste("Accuracy (QCBA):",acc_cba))
```
On the training data, QCBA provides the same accuracy as CBA but with fewer rules.

### Under the hood:
The steps taken by QCBA to create the model shown above:

1. **Refit** the data to *finer grid*: this grid has steps corresponding to all unique attribute values appearing in the training data.
2. **Trimming** (optional): the literals in discovered rules are trimmed so that they do not contain regions not covered by data.
3. **Extension**: the ranges of literals in the body of each rule are extended. The range of each literal is increased one literal and one boundary at a time. The extension is generally accepted only if it improves rule confidence. To overcome local minima, the extension process can provisionally accept drop in confidence compared to the seed rule
4. **Postpruning**: second iteration of data coverage pruning

Additionally, QCBA supports two other features, which will be demonstrated on another dataset (TBD).
5. **Attribute pruning**: Remove redundant attributes from rules. Attribute is considered redundant if its removal does not decrease rule confidence.
6. **Default rule overlap  pruning**:  Default rule overlap iterates through all rules classifying into the same class as the default rule. These rules all overlap with the default rule and are thus *candidates* for pruning. They can be removed only if their removal will not change the classification of the instances (or regions -- second type of default overlap pruning) they cover by rules that are below them.

Steps 1-4 will be demonstrated in detail in the following.
First, we will setup some code for visualization of the progress of qCBA.


```{r}
plotHumTempRuleDelta<- function(rules, ruleIndex2,ruleIndex1, border = "red",col=rgb(0,0,1,alpha=0.3) )
{
  rule1 <- rules$rules[ruleIndex1]
  rule2 <- rules$rules[ruleIndex2]
  
  temp_coordinates1 <- unlist(regmatches(rule1,regexec("Temperature=.([0-9]+);([0-9]+).",rule1)))
  temp_coordinates2 <- unlist(regmatches(rule2,regexec("Temperature=.([0-9]+);([0-9]+).",rule2)))
  hum_coordinates1 <- unlist(regmatches(rule1,regexec("Humidity=.([0-9]+);([0-9]+).",rule1)))
  hum_coordinates2 <- unlist(regmatches(rule2,regexec("Humidity=.([0-9]+);([0-9]+).",rule2)))
  
  r1_bottom <- temp_coordinates1[2]
  r1_top <- temp_coordinates1[3] 
  r1_left <- hum_coordinates1[2]
  r1_right <- hum_coordinates1[3] 
  r2_bottom <- temp_coordinates2[2]
  r2_top <- temp_coordinates2[3] 
  r2_left <- hum_coordinates2[2]
  r2_right <- hum_coordinates2[3]  
  
  if (r2_right>r1_right)
  {
    r_right<- r2_right
    r_left <- r1_right
    r_top <- r1_top
    r_bottom <- r1_bottom
  }
  else if(r2_left>r1_left)
  {
    r_right<- r2_left
    r_left <- r1_left
    r_top <- r1_top
    r_bottom <- r1_bottom
  }
  else if  (r2_top>r1_top)
  {
    r_right<- r1_right
    r_left <- r1_left
    r_top <- r2_top
    r_bottom <- r1_top
  }  
  else if  (r2_bottom<r1_bottom)
  {
    r_right<- r1_right
    r_left <- r1_left
    r_top <- r1_bottom
    r_bottom <- r2_bottom
  }    
  m <- rect(r_left,r_bottom,r_right,r_top,border=border,col=col)
}

plotRuleInHistory <- function(extendHistory,i,seedRuleConf)
{
  titles=c("Rule is refit to the finer grid","Rule is trimmed", rep("Rule is extended",nrow(extendHistory)-3), "Final rule: no other extend was succcessful")
  curRuleConf <- extendHistory[i,5]
    if (seedRuleConf > curRuleConf  && i>1){
      titles[i] <- paste(titles[i]," (Conditional accept)")
    }
  
  plot(Humidity,Temperature,pch=Class, main=titles[i],cex.lab=0.01, cex.axis=1.5, cex.main=1.5, xlab="", ylab="", ylim=c(20,35),xlim=c(27,65),cex.sub=1.3, sub=paste(extendHistory[i,3], "\n","Supp:",round(extendHistory[i,4],2)," Conf:",round(curRuleConf,2)))
  plotGrid(TRUE,FALSE)
  plotHumTempRule(extendHistory[3],i)
  if (seedRuleConf > curRuleConf && i>1)
  {
    plotHumTempRuleDelta(extendHistory,i-1,i,border="red",col=rgb(1,0,0,alpha=0.5))
  }  
  
}
inspected_rule_RID <- "2"
extendHistory <- rmqCBA@history[rmqCBA@history$RID==inspected_rule_RID,]
base_rule_in_history <- 1
if (trim_literal_boundaries == TRUE)
{
# the base confidence will be taken from the trimmed rule, which is the second rule in history
 base_rule_in_history <- 2
}
seedRuleConf <- rmqCBA@history[rmqCBA@history$RID==inspected_rule_RID,][base_rule_in_history,5]


```

#### Refit: The finer grid
CBA rules stick to a grid that corresponds to results of discretization. The grid used by qCBA corresponds to all unique values appearing in the training data.

```{r}

interestingRuleAsText <-  paste(paste(unlist(interestingRule$lhs[1]),collapse=''),paste(unlist(interestingRule$rhs[1]),collapse=''),sep=" => ")
plot(Humidity,Temperature,pch=Class,main="CBA-generated rule on original grid", sub=paste(interestingRuleAsText, "Supp:",round(interestingRule$support,2)," Conf:",round(interestingRule$confidence,2)),cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.15)
plotGrid(FALSE)
plotHumTempRule(rmCBA@rules,3)

```


The same rule from the CBA classifier plotted on the finer grid. 

```{r}
plot(Humidity,Temperature,pch=Class, main="The finer grid",cex.lab=1.5, cex.axis=1.5,  xlab="", ylab="", cex.main=1.5, cex.sub=1.15)
plotGrid()
plotHumTempRule(rmCBA@rules,3)
m<-dev.copy(png,filename="qcba.png")
m<-dev.off()
```

Let's zoom in and look at how QCBA refit the rule:
```{r}
plotRuleInHistory(extendHistory,1,seedRuleConf)
```
#### Trimming
Rule  is shaved of any boundaries that are not backed by correctly classified instances. 

```{r}
plotRuleInHistory(extendHistory,2,seedRuleConf)
```

#### Extension -- the complete process
The process proceeds as follows:
1. Rule is refit to finer grid. Boundaries shrink, confidence and support is unaffected.
2. Rule is trimmed: it is shaved of one misclassified data point, confidence rises from 0.6 to 0.75
3.-9. Rule coverage is extended. Confidence and support is unaffected.
10. Left boundary on Humidity conditionally extends - one additional misclassified and one correctly classified data point is covered. Confidence drops to 0.67.
11. Left boundary  on Humidity conditionally extends - one additional correctly classified point is covered. Confidence increases to 0.71, but is still below 0.75.
12. Left boundary  on Humidity extends - one additional correctly classified point is covered. Confidence returns 0.75.
13. Left boundary  on Humidity extends. Confidence and support is unaffected. Final rule.

Note that QCBA improved confidence of rule 2 from initial value of 0.6 to 0.75  and support from 0.08 to 0.17.

```{r fig.width=7, fig.height=6, fig.show='animate'}
for (i in 1:nrow(extendHistory)) {
  plotRuleInHistory(extendHistory,i,seedRuleConf)
}
```

#### Postpruning 
As a result of the extension process, the data matched by the individual rules change. Within postprocessing, the extended rules are resorted and pruned again using CBA data coverage pruning.

Result of the extension process:
```{r results='hide',message=FALSE}
rmqCBA <- qcba(cbaRuleModel=rmCBA,datadf=data_raw, extendType="numericOnly",trim_literal_boundaries = TRUE, postpruning = "none",  createHistorySlot=TRUE,loglevel = "WARNING")
print(rmqCBA@rules)
```

Result of postpruning:
```{r results='hide'}
rmqCBA_pruned <- qcba(cbaRuleModel=rmCBA,datadf=data_raw, extendType="numericOnly",trim_literal_boundaries = TRUE, postpruning = "cba",  createHistorySlot=TRUE,loglevel = "WARNING")
print(rmqCBA_pruned@rules)
```
Last two rules with non-empty antecedent were replaced by data coverage pruning by the default rule:
```{r results='hide'}
rmqCBA@rules[4:5,1]
```
with default rule:
```{r results='hide'}
rmqCBA_pruned@rules[4,1]
```
This replacement results in same training set error with fewer rules.

Training set error for the original rule list:
```{r results='hide', message=FALSE}

  prediction_qcba<-predict(rmqCBA,data_raw,discretize=FALSE)
  acc_qcba <- CBARuleModelAccuracy(prediction_qcba, data_raw[[classAtt]])
  print(paste("Accuracy (QCBA - without postpruning):",acc_cba))
```
Error for the pruned rule list: 
```{r results='hide', message=FALSE}
  prediction_qcba<-predict(rmqCBA_pruned,data_raw,discretize=FALSE)
  acc_qcba <- CBARuleModelAccuracy(prediction_qcba, data_raw[[classAtt]])
  print(paste("Accuracy (QCBA with postpruning):",acc_cba))
```

### Other configuration options

#### Default rule overlap pruning
Default rule overlap iterates through all rules classifying into the same class as the default rule. These rules all overlap with the default rule and are thus *candidates* for pruning. However, they can be removed only if their removal will not change the classification of the instances (or regions -- see below) they cover by rules that are below them. Recall that for prediction CBA uses the first rule in the rule list. Therefore, the algorithm checks whether the region (transactions) matched by the antecedent of the candidate overlaps with region matched by any of the remaining rules (*potential clashing rule*) classifying instances into a different class that are below the candidate in the rule list. If there are no such rules, the candidate can be removed (pruned). 

There are two ways how to check the overlap between the candidate and a potential clashing rule. 
1. Check the regions matched by the antecedents of the candidate and the potential clashing rule by analyzing the boundaries of the rules. 
2. Check overlap in transactions covered by the antecedent of the candidate rule and the antecedent of the potential clashing rule in the training data.

##### Default rule overlap (transaction-based)
Let's us create a different classifier by lowering the minimum support threshold and disabling trimming.
```{r results='hide',message=FALSE}
# we will use support of 1 instance
trim_literal_boundaries = FALSE
supp = 1
sink("/dev/null")
  rules <- apriori(txns, parameter = list(confidence = 0.5, support= supp/nrow(data_discr), minlen=1, maxlen=3), appearance=appearance)
  rmCBA <- cba_manual(data_raw,  rules, txns, appearance$rhs, classAtt, cutp= list(), pruning_options=NULL)
  rmqCBA <- qcba(cbaRuleModel=rmCBA,datadf=data_raw, extendType="numericOnly",trim_literal_boundaries = trim_literal_boundaries, postpruning = "cba", defaultRuleOverlapPruning="noPruning", createHistorySlot=TRUE,loglevel = "WARNING")
  sink()
print(rmqCBA@rules)
```

By activating default rule overlap pruning, we can reduce the number of rules in the classifier by 1.
```{r results='hide',message=FALSE}
sink("/dev/null")
  rmqCBA_dro <- qcba(cbaRuleModel=rmCBA,datadf=data_raw, extendType="numericOnly",trim_literal_boundaries = trim_literal_boundaries, postpruning = "cba", defaultRuleOverlapPruning="transactionBased", createHistorySlot=FALSE,loglevel = "WARNING")
  sink()
print(rmqCBA_dro@rules)
```
Rule #6 in the original classifier is not needed.
Rule #6:

```{r results='hide',message=FALSE}
print(rmqCBA@rules[6,1])
```
This rule assigns into Class 3 - the same class as the default rule in the end of the classifier. Let's look at rules between #6 and the default rule #11:
```{r results='hide',message=FALSE}
print(rmqCBA@rules[6:11,1])
```
There is no rule below #6 that would prevent the **training** instances covered by #6 from being classified by the default rule (which has the same class as #6). 
Rule #6 is drawn in grey in the following figure, the remaining rules below it are drawn in blue and green. 


```{r}
plot(Humidity,Temperature,pch=Class, main="Rules #6 to #11 (default rule pruning OFF)",cex.lab=1.5, cex.axis=1.5,  xlab="", ylab="", cex.main=1.5, cex.sub=1.15)
plotGrid()
for (i in 6:11) {
plotHumTempRule(rmqCBA@rules,i)
}
```
When Default rule overlap pruning is activated,  rules such as #6 are  removed and the  area left for classification to the default rule, which comes as last (default rule is plotted in grey).

```{r}
plot(Humidity,Temperature,pch=Class, main="Rules #6 to #10 (default rule pruning ON)",cex.lab=1.5, cex.axis=1.5,  xlab="", ylab="", cex.main=1.5, cex.sub=1.15)
plotGrid()
for (i in 6:10) {
plotHumTempRule(rmqCBA_dro@rules,i)
}
```

##### Default rule overlap (range-based)
Range-based default rule pruning looks at rules below each rule that classifies to the default class  and inspects whether the rules below it can divert instances from being classified by the default rule. The difference from the transaction-based method is that it is inspected wether the regions covered by the rules do not overlap rather than training transactions.  While range-based pruning thus guarantees a solution that generalizes beyond the training data. It is perfectly safe to remove rules detected as redundant by range-based default rule overlap.

The disadvantage is that range based  pruning is not very uneffective. In realistically sized rule lists spanning mutliple dimensions, the odds that there will be a clashing rule for any candidate rule is very high and thus no rules will be removed. An alternative way is to judge overlap between two rules based on whether they have any transactions in common.  

In our toy case, range-based pruning does not remove any rule. Rule #6 is not removed, because it shares a boundary on Temperature (34) with rule #8.

```{r}
plot(Humidity,Temperature,pch=Class, main="R #6 and #8 intersect (range-based pruning is ineffective)",cex.lab=1.5, cex.axis=1.5,  xlab="", ylab="", cex.main=1.5, cex.sub=1.15)
plotGrid()
plotHumTempRule(rmqCBA@rules,6)
plotHumTempRule(rmqCBA@rules,8)
```

#### Attribute pruning demonstration

To demonstrate attribute pruning, we need to use dataset with higher number of attributes than humtemp has. Let's use the iris dataset.

Rule list without attribute pruning:

```{r message=FALSE}
set.seed(111)
allData <- datasets::iris[sample(nrow(datasets::iris)),]
trainFold <- allData[1:100,]
testFold <- allData[101:nrow(datasets::iris),]
rulelearning_options <- list(find_conf_supp_thresholds = FALSE,minconf = 0.5, minsupp = 0.01, minlen = 1, maxlen = 6, maxtime = 10,trim = FALSE,target_rule_count =10)
rmCBAiris <- cba(trainFold, classAtt="Species", rulelearning_options = rulelearning_options)
rmqCBAiris <- qcba(cbaRuleModel=rmCBAiris,datadf=trainFold,extendType="numericOnly", postpruning="cba", defaultRuleOverlapPruning="noPruning")
print(rmqCBAiris@rules)
```
The accuracy of the model:
```{r message=FALSE}
prediction_iris <- predict(rmqCBAiris,testFold,"firstRule")
acc <- CBARuleModelAccuracy(prediction_iris, testFold[[rmqCBA@classAtt]])
print(acc)

```
Rule list with attribute pruning:

```{r message=FALSE}
rmqCBAiris <- qcba(cbaRuleModel=rmCBA,datadf=trainFold, attributePruning = TRUE, extendType="numericOnly", postpruning="cba", defaultRuleOverlapPruning="noPruning")
print(rmqCBAiris@rules)
```

```{r message=FALSE}
prediction_iris <- predict(rmqCBAiris,testFold,"firstRule")
acc <- CBARuleModelAccuracy(prediction_iris, testFold[[rmqCBA@classAtt]])
print(acc)
```
## Under the hood

### Speeding up conditional accept
The default value of the minCondImprovement parameter is -1. This parameter value ensures exhaustive search for extensions, but can be slow on large datasets or datasets with many distinct values. The closer this parameter value will be to 0, the faster the execution will generally be. 

```{r}
start.time <- Sys.time()
for (i in 1:100)
{
 rmqCBA <- qcba(cbaRuleModel=rmCBA,datadf=trainFold,extendType="numericOnly", minCondImprovement=-1, postpruning="cba", defaultRuleOverlapPruning="noPruning")
}
end.time <- Sys.time()
message (paste("100 executions took:", round(end.time - start.time,2), " seconds"))
```
```{r}
start.time <- Sys.time()
for (i in 1:100)
{
 rmqCBA <- qcba(cbaRuleModel=rmCBA,datadf=trainFold,extendType="numericOnly", minCondImprovement=-0.05, postpruning="cba", defaultRuleOverlapPruning="noPruning")
}
end.time <- Sys.time()
message (paste("100 executions took:", round(end.time - start.time,2), " seconds"))
```
Improvement in execution time gained  on this small dataset by changin  minCondImprovement from -1 to -0.05 is about 30%.

### Debugging qCBA execution in Java.
The CBA model is passed by the R code to a Java .jar file, which performs the QCBA model learning. The QCBA model is then returned to R. 

#### Debugging qCBA execution in Java.
To debug the "humtemp" dataset:


1. Let's create "debug" folder, where we will store the rmCBA model.
```{r}
        basePath <-  tempdir()
        dir.create(file.path(basePath, "debug"), showWarnings = FALSE)
        rulesPath <-paste(basePath,"debug","humtemp.arules",sep=.Platform$file.sep)
        write.csv(as(rmCBA@rules,"data.frame"), rulesPath, row.names=TRUE,quote = TRUE)
        outputDataPath <- paste(basePath,"debug",'humtemp.csv', sep=.Platform$file.sep)
        write.csv(humtemp,file=outputDataPath,row.names=FALSE)
```

Let's create the configuration file for QCBA. 
```{r}
extendType="numericOnly"
trimLiteralBoundaries = FALSE
attributePruning =TRUE
defaultRuleOverlapPruning = "rangeBased" #noPruning,transactionBased,rangeBased
postpruning = "cba" #none,cba,greedy
dataTypes <- paste(rmCBA@attTypes, collapse = ',') 
classAtt <- colnames(humtemp)[length(humtemp)] #last attribute
outputPath <- paste(basePath,"debug",'humtemp-qcba.arules', sep=.Platform$file.sep)

x=paste('<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">',
        "<properties>\n",
        "<entry key=\"Method\">extend</entry>\n",
        "<entry key=\"RulesPath\">", rulesPath, "</entry>\n",
        "<entry key=\"TrainDataPath\">", outputDataPath,"</entry>\n",
        "<entry key=\"ExtendType\">",extendType,"</entry>\n",
        "<entry key=\"AttributePruning\">",attributePruning, "</entry>\n",
        "<entry key=\"Trimming\">",trimLiteralBoundaries, "</entry>\n",
        "<entry key=\"DefaultRuleOverlapPruning\">",defaultRuleOverlapPruning, "</entry>\n",
        "<entry key=\"Postpruning\">",postpruning, "</entry>\n",
        "<entry key=\"DataTypes\">", dataTypes,'</entry>\n',
        "<entry key=\"TargetAttribute\">", classAtt,'</entry>\n',
        "<entry key=\"OutputPath\">", outputPath,'</entry>\n',
        "</properties>", sep="")

        qcbaFilePath <-paste(basePath,"debug","humtemp-conf.xml",sep=.Platform$file.sep)
        write(x, file = qcbaFilePath,
              ncolumns = 1,
              append = FALSE, sep = ",")
print(paste("Run as: ", "java -jar AC1.jar ", qcbaFilePath, sep=""))
print(paste("QCBA model will be written to:",outputPath))
```

#### Debugging qCBA execution in Java.
To debug the "iris" dataset:


1. Let's create "debug" folder, where we will store the rmCBA model.
```{r}
        basePath <-  tempdir()
        dir.create(file.path(basePath, "debug"), showWarnings = FALSE)
        rulesPath <-paste(basePath,"debug","iris.arules",sep=.Platform$file.sep)
        write.csv(as(rmCBAiris@rules,"data.frame"), rulesPath, row.names=TRUE,quote = TRUE)
        outputDataPath <- paste(basePath,"debug",'iris-train.csv', sep=.Platform$file.sep)
        write.csv(trainFold,file=outputDataPath,row.names=FALSE)
```

Let's create the configuration file for QCBA. 
```{r}
extendType="numericOnly"
trimLiteralBoundaries = FALSE
attributePruning =TRUE
defaultRuleOverlapPruning = "noPruning" #noPruning,transactionBased,rangeBased
postpruning = "cba" #none,cba,greedy
dataTypes <- paste(rmCBAiris@attTypes, collapse = ',') 
classAtt <- colnames(trainFold)[length(trainFold)] #last attribute
outputPath <- paste(basePath,"debug",'iris-qcba.arules', sep=.Platform$file.sep)

x=paste('<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">',
        "<properties>\n",
        "<entry key=\"Method\">extend</entry>\n",
        "<entry key=\"RulesPath\">", rulesPath, "</entry>\n",
        "<entry key=\"TrainDataPath\">", outputDataPath,"</entry>\n",
        "<entry key=\"ExtendType\">",extendType,"</entry>\n",
        "<entry key=\"AttributePruning\">",attributePruning, "</entry>\n",
        "<entry key=\"Trimming\">",trimLiteralBoundaries, "</entry>\n",
        "<entry key=\"DefaultRuleOverlapPruning\">",defaultRuleOverlapPruning, "</entry>\n",
        "<entry key=\"Postpruning\">",postpruning, "</entry>\n",
        "<entry key=\"DataTypes\">", dataTypes,'</entry>\n',
        "<entry key=\"TargetAttribute\">", classAtt,'</entry>\n',
        "<entry key=\"OutputPath\">", outputPath,'</entry>\n',
        "</properties>", sep="")

        qcbaFilePath <-paste(basePath,"debug","iris-conf.xml",sep=.Platform$file.sep)
        write(x, file = qcbaFilePath,
              ncolumns = 1,
              append = FALSE, sep = ",")
print(paste("Run as: ", "java -jar AC1.jar ", qcbaFilePath, sep=""))
print(paste("QCBA model will be written to:",outputPath))
```



