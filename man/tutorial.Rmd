---
title: "qCBA tutorial"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## About Quantitative CBA

We propose a postprocessing algorithm for ARC classification algorithm CBA (Liu, 1998), which reverts to the original attribute space to ``edit'' discovered association rules, refining the scope of literals in the antecedent of the rules.  As a consequence, the fit of the individual rules to data improves, rendering some of the rules comprising the model as redundant. These rules can be removed, making the resulting classifier smaller. The viable properties of CBA models that make these rule lists comprehensible, such as one-rule classification and crisp rules, are retained. The postprocessing is conceptually fast, because it is performed on a relatively small number of rules that passed the data coverage pruning in CBA. 

### Novelty

* First "quantitative" association rule classification algorithm.
* Conceptually different from existing quantitative association rule learning algorithms such as QuantMiner or  NAR-Discovery.

### Benchmark

QCBA was evaluated on 22 standard UCI datasets against standard as well as state-of-the-art symbolic classification algorithms (such as RIPPER, FURIA, CBA). The evaluation is fully reproducible using the [arcBench package](https://github.com/kliegr/arcBench) and meets industry standards (same folds, metaparameter optimization, etc.). The evaluation shows that QCBA produces  classifiers with about 1/3 less rules than CBA while retaining comparable accuracy. 

## Library
The QCBA implementation is in Java. It is also available via an [R package wrapper](https://github.com/kliegr/QCBA), which we will used for this example.

```{r results='hide', message=FALSE}
library(qCBA)
attach(humtemp)
```
## Data

Let's look at sample data for this example. There are two explanatory attributes (Temperature and Humidity). The target attribute is preference (e.g. subjective comfort level). 


```{r results='hide', message=FALSE}
attach(humtemp)
```

The first few rows of the data.


```{r}
head(humtemp)
```

And a scatter plot.
```{r}
plot(Humidity,Temperature,pch=as.character(Class))
```

## Building a CBA classifier
Association rule learning requires discretized data.
In this case, we perform simple equidistant binning.


```{r}
  #custom discretization
  data_raw<-humtemp
  data_discr <- humtemp
  temp_breaks <- seq(from=15,to=45,by=5)
  hum_breaks <- c(0,40,60,80,100)
  temp_unique_vals <- setdiff(unique(Temperature),temp_breaks)
  hum_unique_vals <- setdiff(unique(Humidity),hum_breaks)
  data_discr[,1]<-cut(Temperature,breaks=temp_breaks)
  data_discr[,2]<-cut(Humidity,breaks=hum_breaks)
  #change interval syntax from (15,20] to (15;20], which is required by MARC
  data_discr[,1]<-as.factor(unlist(lapply(data_discr[,1], function(x) {gsub(",", ";", x)})))
  data_discr[,2]<-as.factor(unlist(lapply(data_discr[,2], function(x) {gsub(",", ";", x)})))
  
  data_discr[,3] <- as.factor(Class)
  head(data_discr)

```
The discretization split the data space into rectangular regions. Given that we have two attributes, the discovered rule can only correspond to a rectangular region with *borders aligned to the grid*. If we had more than two attributes, the discovered rule would delimit a hypercube.

```{r}
plotGrid <- function(plotFineGrid=TRUE, plotDiscrGrid=TRUE)
{
  if (plotDiscrGrid)
  {

    for (i in temp_breaks[-1])
  {
    abline(h=i, lty=2)
  }
  for (i in hum_breaks[-1])
  {
    abline(v=i, lty=2)
  }
  }
  if (plotFineGrid)
  {
    for (i in temp_unique_vals[-1])
    {
      abline(h=i, lty=3, col="grey")
    }
    for (i in hum_unique_vals[-1])
    {
      abline(v=i, lty=3, col="grey")
    }  
  }
}

plot(Humidity,Temperature,pch=as.character(Class))
plotGrid(FALSE)


```

The next step is mining of association rules. The rule mining is constrained to rules that have values of the Class attribute in the consequent.

```{r results='hide', message=FALSE}
sink("/dev/null")
txns <- as(data_discr, "transactions")
  rules <- apriori(txns, parameter = list(confidence = 0.75, support= 3/nrow(data_discr), minlen=1, maxlen=5))
  inspect(rules)
sink()
inspect(rules)
```

The two rules can be visualized in the feature space as rectangular regions. 

```{r}
#as.character(Class)
plot(Humidity,Temperature,pch=Class,main="CBA model",cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)

plotGrid(FALSE)

plotHumTempRule<- function(rules, ruleIndex, border = "blue",col=rgb(0,0,1,alpha=0.3) )
{
  if (typeof(rules)=="S4")
  {
    # rules is a arules rule model
    # sink: inspect also sends rules to the standard output
    sink("/dev/null")
    r <- inspect(rules)[ruleIndex,]
    sink()
    rule <- paste(unlist(r$lhs[1]),collapse='')
  }
  else
  {
    # rules is a list of rules output by qCBA
    #rule <- rules[ruleIndex,1]
    rule <- rules$rules[ruleIndex]
  }
  temp_coordinates<-unlist(regmatches(rule,regexec("Temperature=.([0-9]+);([0-9]+).",rule)))
  if (length(temp_coordinates)==0)
  {
    #if the temperature literal is missing in the rule, use the following coordinates
    temp_coordinates=c(0,0,50)
  }
  
  hum_coordinates<-unlist(regmatches(rule,regexec("Humidity=.([0-9]+);([0-9]+).",rule)))
  m <- rect(hum_coordinates[2], temp_coordinates[2], hum_coordinates[3], temp_coordinates[3],border=border,col=col)
}


plotHumTempRule(rules,1,border = "blue",col=rgb(0,0,1,alpha=0.3))
plotHumTempRule(rules,2,border = "green",col=rgb(0,1,0,alpha=0.3))
m <- dev.copy(png,filename="cba.png")
m <- dev.off()
```


Out of the two discovered rules, we will create a CBA classifier.
This means that the rules will be 

1. sorted according to confidence support and length
2. subject to simultaneous data coverage pruning & default rule pruning:
 + data coverage pruning: algorithm iterates through the rules in the sort order removing any rule which does not correctly cover any instances (instances correctly covered by rules above the current rule have been removed)
 + default rule pruning: the algorithm iterates through the rules in the sort order, and cuts off the list once the current rule would result in worse accuracy than a default rule inserted at that place
4. a default rule is inserted at the bottom of the list. Default rule is a rule with empty antecedent and consequent predicting a majority class left in the training data once the previous rules in the classifier were applied.

```{r message=FALSE}
classAtt="Class"
  appearance <- getAppearance(data_discr, classAtt)
  # Note that we are calling `cba_manual()` instead of cba() because we want for demonstration purposes to construct the classifier from a user-generated rule list.
  rmCBA <- cba_manual(data_raw,  rules, txns, appearance$rhs, classAtt, cutp= list(), pruning_options=NULL)
```

The data and the setting of the  task was constructed so that the CBA data coverage pruning does not remove any rule from the classifier. CBA only added default rule to the end, which ensures that the rule list covers every possible instance.

```{r}
inspect(rmCBA@rules)
```
The accuracy of this model on training data:
```{r results='hide', message=FALSE}
  prediction_cba<-predict(rmCBA,data_discr,discretize=FALSE)
  acc_cba <- CBARuleModelAccuracy(prediction_cba, data_discr[[classAtt]])
  print(paste("Accuracy (CBA):",acc_cba))
```
## Postprocessing CBA output with Quantitative CBA (QCBA)
QCBA postprocesses CBA classifier created over discretized numeric attributes. QCBA requires on the input also the original raw undiscretized (continuous) data. 

### Intro to QCBA 
The steps taken by QCBA:

1. **Refit** the data to *finer grid*: this grid has steps corresponding to all unique attribute values appearing in the training data.
2. **Trimming** (optional): the literals in discovered rules are trimmed so that they do not contain regions not covered by data.
3. **Extension**: the ranges of literals in the body of each rule are extended. The range of each literal is increased one literal and one boundary at a time. The extension is generally accepted only if it improves rule confidence. To overcome local minima, the extension process can provisionally accept drop in confidence compared to the seed rule within bounds set by the `minCondImprovement` threshold. There are several extension strategies:
+ `ConfImprovementAgainstLastConfirmedExtension`: extension is accepted only if the extended rule is better by `minImprovement` than the last confirmed extension (or the original rule). This is the most conservative strategy that produces generally produces highest confidence rules.
+ `ConfImprovementAgainstSeedRule`: extension is accepted only if the extended rule is better by minImprovement than the original rule.  This strategy is better fitted to overcome noise in the data.
This strategy can result in "wider" rules while at least still preserving the confidence of the original seed rule (assuming that `minImprovement>=0`).
+ `MinConf`: extension is accepted as long as the extended rule has at least prespecified value of confidence . This strategy produces the widest possible extension, producing rules that at least preserve the confidence threshold `minConf`, which can be the same as confidence threshold used for CBA classifier building.
4. **Continuous pruning** (optional): this essentially corresponds to second iteration of data coverage pruning (first was performed during CBA classifier building), which is performed immediately after a rule is extended.
5. **Postpruning (optional)**: second iteration of data coverage pruning is performed *after* all rules have been extended and resorted.  



###QCBA model

To build a model, `qcba` needs a cba model and raw (undiscretized) data. Note that number of additional parameters can be also specified - these were left to their default values.
```{r results='hide'}
rmqCBA <- qcba(cbaRuleModel=rmCBA,datadf=data_raw,extensionStrategy= "ConfImprovementAgainstLastConfirmedExtension", trim_literal_boundaries = TRUE, continuousPruning = FALSE, postpruning = FALSE, minImprovement=0, minCondImprovement=0, minConf = 0.5, createHistorySlot=TRUE,loglevel = "WARNING")
print(rmqCBA@rules)
```

As we can notice, the number of rules on the output remained unchanged. However, the boundaries for most literals (attribute-value pairs) in the rules have changed.

#### The finer grid
CBA rules stick to a grid that corresponds to results of discretization (figure left below). The grid used by QCBA corresponds to all unique values appearing in the training data (figure right below).

```{r}
plot(Humidity,Temperature,pch=as.character(Class))
plotGrid(FALSE)
plot(Humidity,Temperature,pch=as.character(Class))
plotGrid(TRUE)

```


#### QCBA result
The QCBA classifier plotted on the finer grid. 

```{r}
plot(Humidity,Temperature,pch=Class, main="QCBA model",cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
plotGrid()
plotHumTempRule(rmqCBA@rules,1,border = "blue",col=rgb(0,0,1,alpha=0.3))
plotHumTempRule(rmqCBA@rules,2,border = "green",col=rgb(0,1,0,alpha=0.3))
m<-dev.copy(png,filename="qcba.png")
m<-dev.off()
```
If we compare this figure with the one showing CBA output, there are the following observations:

1. Rule 1 (blue): the coverage of the rule has been effectively narrowed to strictly cover only instances covered by the rule.
2. Rule 2 (green): the coverage of the rule has been changed to exclude one misclassified instance, and include three other correctly classified instances.
3. The default rule is unchanged. 

#### Extension strategy Confidence Improvement Against Last Confirmed Extension)

```{r fig.width=7, fig.height=6, fig.show='animate'}
extendHistory <- rmqCBA@history[rmqCBA@history$RID=="1",]
for (i in 1:nrow(extendHistory)) {
  titles=c("Rule is refit to the finer grid","Rule is trimmed", rep("Rule is extended",nrow(extendHistory)-3), "No other extend was succcessful")

  plot(Humidity,Temperature,pch=Class, main=titles[i],cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1, sub=paste(extendHistory[i,3], "Supp:",round(extendHistory[i,4],2)," Conf:",round(extendHistory[i,5],2)))
  plotGrid(TRUE,FALSE)
  plotHumTempRule(extendHistory,i,border = "blue",col=rgb(0,0,1,alpha=0.3))
  }
```

This example used the conservative extension strategy ConfImprovementAgainstLastConfirmedExtension.

Note that QCBA improved confidence of rule 2 from 0.75 to 1.0 and support from 0.09 to 0.18.

### Extension strategy "Confidence Improvement Against Seed Rule"

```{r results='hide'}
rmqCBA <- qcba(cbaRuleModel=rmCBA,datadf=data_raw,extensionStrategy= "ConfImprovementAgainstSeedRule", trim_literal_boundaries = TRUE, continuousPruning = FALSE, postpruning = FALSE, minImprovement=0, minCondImprovement=-1, minConf = 0.5, createHistorySlot=TRUE,loglevel = "WARNING")
print(rmqCBA@rules)
```


```{r fig.width=7, fig.height=6, fig.show='animate'}
plotHumTempRuleDelta<- function(rules, ruleIndex1,ruleIndex2, border = "red",col=rgb(0,0,1,alpha=0.3) )
{
  # rules is a list of rules output by qCBA
  #rule <- rules[ruleIndex,1]
  rule1 <- rules$rules[ruleIndex1]
  rule2 <- rules$rules[ruleIndex2]
  temp_coordinates1 <- unlist(regmatches(rule1,regexec("Temperature=.([0-9]+);([0-9]+).",rule1)))
  temp_coordinates2 <- unlist(regmatches(rule2,regexec("Temperature=.([0-9]+);([0-9]+).",rule2)))
  hum_coordinates1 <- unlist(regmatches(rule1,regexec("Humidity=.([0-9]+);([0-9]+).",rule1)))
  hum_coordinates2 <- unlist(regmatches(rule2,regexec("Humidity=.([0-9]+);([0-9]+).",rule2)))
  r1_bottom <- temp_coordinates1[2]
  r1_top <- temp_coordinates1[3] 
  r1_left <- hum_coordinates1[2]
  r1_right <- hum_coordinates1[3] 
  r2_bottom <- temp_coordinates2[2]
  r2_top <- temp_coordinates2[3] 
  r2_left <- hum_coordinates2[2]
  r2_right <- hum_coordinates2[3]  
  if (r2_right>r1_right)
  {
    r_right<- r2_right
    r_left <- r1_right
    r_top <- r1_top
    r_bottom <- r1_bottom
  }
  else if  (r2_left>r1_left)
  {
    r_right<- r2_left
    r_left <- r1_left
    r_top <- r1_top
    r_bottom <- r1_bottom
  }
  else if  (r2_top>r1_top)
  {
    r_right<- r1_right
    r_left <- r1_left
    r_top <- r2_top
    r_bottom <- r1_top
  }  
  else if  (r2_bottom<r1_bottom)
  {
    r_right<- r1_right
    r_left <- r1_left
    r_top <- r1_bottom
    r_bottom <- r2_bottom
  }    
  m <- rect(r_left,r_bottom,r_right,r_top,border=border,col=col)
  }
extendHistory <- rmqCBA@history[rmqCBA@history$RID=="1",]
seedRuleConf <- rmqCBA@history[rmqCBA@history$RID=="1",][1,5]
for (i in 1:nrow(extendHistory)) {
  titles=c("Rule is refit to the finer grid","Rule is trimmed", rep("Rule is extended",nrow(extendHistory)-3), "Final rule: no other extend was succcessful")
  curRuleConf <- extendHistory[i,5]
    if (seedRuleConf > curRuleConf ){
      titles[i] <- paste(titles[i]," (Conditional accept)")
    }
  
  plot(Humidity,Temperature,pch=Class, main=titles[i],cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1, sub=paste(extendHistory[i,3], "Supp:",round(extendHistory[i,4],2)," Conf:",round(curRuleConf,2)))
  plotGrid(TRUE,FALSE)
  plotHumTempRule(extendHistory,i,border = "blue",col=rgb(0,0,1,alpha=0.3))
  if (seedRuleConf > curRuleConf )
  {
    plotHumTempRuleDelta(extendHistory,i-1,i, border = "red",col=rgb(1,0,0,alpha=1.0))
  }  
}
```

Note that QCBA improved confidence of  rule 2 from 0.75 to 0.77 and support from 0.09 to 0.29.

